---
id: std-20251127-024523-v8k2
depthUsed: standard
timestamp: 2025-11-27T02:45:23Z
executed: false
originalPrompt: "il tuo obiettivo è verificare che la pipeline intera, descritta sia in @run_pipeline.py che @README.md funzioni perfettamente, che i dati siano validi e che popolino correttamente il database @database/treasury_data.duckdb. Devi attivare il venv per eseguire gli script e verificare il tutto. Sei un esperto developer e gestore di backend. Un altro modo per verificare la validità dei dati è leggere l'output dello script intero in @outputs/pipeline_raw-2025-11-27_02-12-50.md . Assicurati di usare gli mcp tool unitAI (smartk workflow e funzione ask-*) e Serena (che permette una funzione simil LSP per leggere e modificare codice sorgente) in modo appropriato."
---

# Improved Prompt

Objective: Validate the complete Treasury API data pipeline integrity

Requirements:
- Verify all 7 scripts execute successfully in sequence
- Confirm data quality and database population accuracy
- Use existing pipeline output for validation reference

Test Environment:
- Activate Python virtual environment before execution
- Working directory: /home/dawid/Projects/treasury-API-interface
- Database: database/treasury_data.duckdb
- Reference output: outputs/pipeline_raw-2025-11-27_02-12-50.md

Verification Tasks:
1. Pipeline Execution Validation
   - Run run_pipeline.py and verify all scripts complete (0 failures)
   - Confirm execution times are within expected ranges (174.5s baseline)
   - Check for deprecation warnings or errors in output

2. Data Integrity Checks
   - Verify database schema and table population
   - Validate record counts match expected values:
     * fiscal_daily_metrics: 977 records
     * fed_liquidity_daily: 1428 records
     * nyfed_repo_ops: 974 records
     * nyfed_reference_rates: 273 records
     * nyfed_settlement_fails: 202 records
     * liquidity_composite_index: 1426 records
   - Check for NULL values in critical columns
   - Verify date ranges and data freshness

3. Output Validation
   - Compare pipeline output against reference file
   - Verify all 8 report sections generate correctly
   - Check calculated metrics (LCI, spreads, percentages)

Tools to Use:
- mcp__serena tools for code inspection (find_symbol, search_for_pattern)
- mcp__unitAI tools for multi-perspective validation (ask-gemini, smart-workflows)
- Standard Python/DuckDB tools for data verification

Success Criteria:
- All 7 scripts execute with returncode 0
- Database contains expected number of records per table
- No critical data quality issues (missing dates, invalid calculations)
- Output matches expected format and structure
- Zero regression errors compared to baseline run

Expected Output:
- Validation report documenting:
  * Script execution status (pass/fail per script)
  * Database integrity check results
  * Data quality assessment
  * Any discrepancies or issues found
  * Recommendations if issues detected

## Quality Scores
- **Clarity**: 65%
- **Efficiency**: 45%
- **Structure**: 50%
- **Completeness**: 55%
- **Actionability**: 60%
- **Specificity**: 60%
- **Overall**: 58% (needs-improvement)

## Original Prompt
```
il tuo obiettivo è verificare che la pipeline intera, descritta sia in @run_pipeline.py che @README.md funzioni perfettamente, che i dati siano validi e che popolino correttamente il database @database/treasury_data.duckdb. Devi attivare il venv per eseguire gli script e verificare il tutto. Sei un esperto developer e gestore di backend. Un altro modo per verificare la validità dei dati è leggere l'output dello script intero in @outputs/pipeline_raw-2025-11-27_02-12-50.md . Assicurati di usare gli mcp tool unitAI (smartk workflow e funzione ask-*) e Serena (che permette una funzione simil LSP per leggere e modificare codice sorgente) in modo appropriato.
```
